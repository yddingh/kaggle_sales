{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":29781,"databundleVersionId":2887556,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-28T01:50:52.939513Z","iopub.execute_input":"2025-07-28T01:50:52.939875Z","iopub.status.idle":"2025-07-28T01:50:52.948353Z","shell.execute_reply.started":"2025-07-28T01:50:52.939853Z","shell.execute_reply":"2025-07-28T01:50:52.947366Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# input dataset\ntrain = pd.read_csv(\"/kaggle/input/store-sales-time-series-forecasting/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/store-sales-time-series-forecasting/test.csv\")\nstores = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/stores.csv')\nholidays = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/holidays_events.csv', parse_dates=['date'])\noil = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/oil.csv', parse_dates=['date'])\ntransactions = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/transactions.csv', parse_dates=['date'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T01:50:52.949912Z","iopub.execute_input":"2025-07-28T01:50:52.950254Z","iopub.status.idle":"2025-07-28T01:50:54.969582Z","shell.execute_reply.started":"2025-07-28T01:50:52.950219Z","shell.execute_reply":"2025-07-28T01:50:54.968577Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# adjust date formats\ntrain['date'] = pd.to_datetime(train['date'])\ntest['date'] = pd.to_datetime(test['date'])\ntransactions['date'] = pd.to_datetime(transactions['date'])\nholidays['date'] = pd.to_datetime(holidays['date'])\noil['date'] = pd.to_datetime(oil['date'])\n\n# merge the dataset\ntrain = train.merge(stores, on='store_nbr', how='left')\ntest = test.merge(stores, on='store_nbr', how='left')\n\ntrain = train.merge(transactions, on=['date', 'store_nbr'], how='left')\n\ntrain = train.merge(oil, on='date', how='left')\ntest = test.merge(oil, on='date', how='left')\n\nholidays = holidays[['date', 'locale', 'transferred']].rename(columns={'locale': 'holidays_locale'})\ntrain = train.merge(holidays, on='date', how='left', suffixes=('', '_holiday'))\ntest = test.merge(holidays, on='date', how='left', suffixes=('', '_holiday'))\n\n#delete unnecessary column\ntrain.drop(columns=['transactions'], inplace=True)\ntest.drop(columns=['transactions'], inplace=True)\n\n#adjust the order of dataset\ntrain_order = [\n    'id', 'date', 'holidays_locale', 'transferred', 'dcoilwtico',\n    'store_nbr',  'city', 'state', 'type', 'cluster',\n   'onpromotion', 'family', 'sales'\n]\n\ntest_order = [\n    'id', 'date', 'holidays_locale', 'transferred', 'dcoilwtico',\n    'store_nbr', 'city', 'state', 'type', 'cluster',\n    'onpromotion', 'family'\n]\n\ntrain = train[train_order]\ntest = test[test_order]\n\ntrain.info()\ntest.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T01:50:54.970742Z","iopub.execute_input":"2025-07-28T01:50:54.971110Z","iopub.status.idle":"2025-07-28T01:50:58.140886Z","shell.execute_reply.started":"2025-07-28T01:50:54.971076Z","shell.execute_reply":"2025-07-28T01:50:58.139259Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# check the missing values\nprint(\"---missing value---\")\nprint(train.isnull().sum())\n\nprint(\"\\n---unique value---\")\nfor col in train:\n    print(f\"{col}:{train[col].nunique()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T01:51:20.043556Z","iopub.execute_input":"2025-07-28T01:51:20.043854Z","iopub.status.idle":"2025-07-28T01:51:22.007819Z","shell.execute_reply.started":"2025-07-28T01:51:20.043834Z","shell.execute_reply":"2025-07-28T01:51:22.007002Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#fill in the missing value\ntrain['holidays_locale'] = train['holidays_locale'].fillna(False)\ntrain['transferred'] = train['transferred'].fillna(False)\ntrain['dcoilwtico'] = train['dcoilwtico'].interpolate(method='linear')\ntrain['dcoilwtico'] = train['dcoilwtico'].fillna(method='ffill').fillna(method='bfill')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T01:51:48.957145Z","iopub.execute_input":"2025-07-28T01:51:48.957421Z","iopub.status.idle":"2025-07-28T01:51:49.775430Z","shell.execute_reply.started":"2025-07-28T01:51:48.957402Z","shell.execute_reply":"2025-07-28T01:51:49.774493Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# check the missing values\nprint(\"---missing value---\")\nprint(train.isnull().sum())\n\nprint(\"\\n---unique value---\")\nfor col in train:\n    print(f\"{col}:{train[col].nunique()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T01:51:55.320494Z","iopub.execute_input":"2025-07-28T01:51:55.320833Z","iopub.status.idle":"2025-07-28T01:51:57.333263Z","shell.execute_reply.started":"2025-07-28T01:51:55.320810Z","shell.execute_reply":"2025-07-28T01:51:57.332495Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#extract temporal feature\ntrain['year'] = train['date'].dt.year\ntrain['month'] = train['date'].dt.month\ntrain['day'] = train['date'].dt.day\ntrain['dayofweek'] = train['date'].dt.dayofweek\ntrain['weekofyear'] = train['date'].dt.isocalendar().week.astype(int)\ntrain['is_weekend'] = train['dayofweek'].isin([5, 6]).astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T01:52:01.419550Z","iopub.execute_input":"2025-07-28T01:52:01.420061Z","iopub.status.idle":"2025-07-28T01:52:02.007686Z","shell.execute_reply.started":"2025-07-28T01:52:01.420034Z","shell.execute_reply":"2025-07-28T01:52:02.006790Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#extract temporal feature\ntrain['year'] = train['date'].dt.year\ntrain['month'] = train['date'].dt.month\ntrain['day'] = train['date'].dt.day\ntrain['dayofweek'] = train['date'].dt.dayofweek\ntrain['weekofyear'] = train['date'].dt.isocalendar().week.astype(int)\ntrain['is_weekend'] = train['dayofweek'].isin([5, 6]).astype(int)\n\n#delete unnecessary column\ntrain.drop(columns=['date'], inplace=True)\ntest.drop(columns=['date'], inplace=True)\n\n#adjust the order of dataset\ntrain_order = [\n    'id', 'year','month','day','dayofweek','weekofyear','is_weekend', 'holidays_locale', 'transferred', \n    'dcoilwtico',\n    'store_nbr', 'city', 'state', 'type', 'cluster',\n    'onpromotion', 'family', 'sales'\n]\n\ntest_order = [\n    'id', 'year','month','day','dayofweek','weekofyear','is_weekend','holidays_locale', 'transferred', \n    'dcoilwtico',\n    'store_nbr',  'city', 'state', 'type', 'cluster',\n   'onpromotion', 'family'\n]\n\ntrain = train[train_order]\ntest = test[test_order]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T01:52:05.227728Z","iopub.execute_input":"2025-07-28T01:52:05.228039Z","iopub.status.idle":"2025-07-28T01:52:06.325496Z","shell.execute_reply.started":"2025-07-28T01:52:05.228016Z","shell.execute_reply":"2025-07-28T01:52:06.324212Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.info","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T01:52:20.447187Z","iopub.execute_input":"2025-07-28T01:52:20.447516Z","iopub.status.idle":"2025-07-28T01:52:20.459263Z","shell.execute_reply.started":"2025-07-28T01:52:20.447492Z","shell.execute_reply":"2025-07-28T01:52:20.458560Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T01:50:58.151354Z","iopub.status.idle":"2025-07-28T01:50:58.151690Z","shell.execute_reply.started":"2025-07-28T01:50:58.151554Z","shell.execute_reply":"2025-07-28T01:50:58.151571Z"}},"outputs":[],"execution_count":null}]}