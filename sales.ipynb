{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":29781,"databundleVersionId":2887556,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-05T04:32:30.836971Z","iopub.execute_input":"2025-08-05T04:32:30.837215Z","iopub.status.idle":"2025-08-05T04:32:31.201381Z","shell.execute_reply.started":"2025-08-05T04:32:30.837192Z","shell.execute_reply":"2025-08-05T04:32:31.200254Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/store-sales-time-series-forecasting/oil.csv\n/kaggle/input/store-sales-time-series-forecasting/sample_submission.csv\n/kaggle/input/store-sales-time-series-forecasting/holidays_events.csv\n/kaggle/input/store-sales-time-series-forecasting/stores.csv\n/kaggle/input/store-sales-time-series-forecasting/train.csv\n/kaggle/input/store-sales-time-series-forecasting/test.csv\n/kaggle/input/store-sales-time-series-forecasting/transactions.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# input dataset\ntrain = pd.read_csv(\"/kaggle/input/store-sales-time-series-forecasting/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/store-sales-time-series-forecasting/test.csv\")\nstores = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/stores.csv')\nholidays = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/holidays_events.csv', parse_dates=['date'])\noil = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/oil.csv', parse_dates=['date'])\ntransactions = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/transactions.csv', parse_dates=['date'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T04:32:31.203820Z","iopub.execute_input":"2025-08-05T04:32:31.204764Z","iopub.status.idle":"2025-08-05T04:32:34.612440Z","shell.execute_reply.started":"2025-08-05T04:32:31.204735Z","shell.execute_reply":"2025-08-05T04:32:34.611430Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# adjust date formats\ntrain['date'] = pd.to_datetime(train['date'])\ntest['date'] = pd.to_datetime(test['date'])\ntransactions['date'] = pd.to_datetime(transactions['date'])\nholidays['date'] = pd.to_datetime(holidays['date'])\noil['date'] = pd.to_datetime(oil['date'])\n\n# merge the dataset\ntrain = train.merge(stores, on='store_nbr', how='left')\ntest = test.merge(stores, on='store_nbr', how='left')\n\ntrain = train.merge(transactions, on=['date', 'store_nbr'], how='left')\n\ntrain = train.merge(oil, on='date', how='left')\ntest = test.merge(oil, on='date', how='left')\n\nholidays = holidays[['date', 'locale', 'transferred']].rename(columns={'locale': 'holidays_locale'})\ntrain = train.merge(holidays, on='date', how='left', suffixes=('', '_holiday'))\ntest = test.merge(holidays, on='date', how='left', suffixes=('', '_holiday'))\n\ntrain.info()\ntest.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T04:32:34.613435Z","iopub.execute_input":"2025-08-05T04:32:34.613730Z","iopub.status.idle":"2025-08-05T04:32:38.009729Z","shell.execute_reply.started":"2025-08-05T04:32:34.613707Z","shell.execute_reply":"2025-08-05T04:32:38.008785Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3054348 entries, 0 to 3054347\nData columns (total 14 columns):\n #   Column           Dtype         \n---  ------           -----         \n 0   id               int64         \n 1   date             datetime64[ns]\n 2   store_nbr        int64         \n 3   family           object        \n 4   sales            float64       \n 5   onpromotion      int64         \n 6   city             object        \n 7   state            object        \n 8   type             object        \n 9   cluster          int64         \n 10  transactions     float64       \n 11  dcoilwtico       float64       \n 12  holidays_locale  object        \n 13  transferred      object        \ndtypes: datetime64[ns](1), float64(3), int64(4), object(6)\nmemory usage: 326.2+ MB\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 28512 entries, 0 to 28511\nData columns (total 12 columns):\n #   Column           Non-Null Count  Dtype         \n---  ------           --------------  -----         \n 0   id               28512 non-null  int64         \n 1   date             28512 non-null  datetime64[ns]\n 2   store_nbr        28512 non-null  int64         \n 3   family           28512 non-null  object        \n 4   onpromotion      28512 non-null  int64         \n 5   city             28512 non-null  object        \n 6   state            28512 non-null  object        \n 7   type             28512 non-null  object        \n 8   cluster          28512 non-null  int64         \n 9   dcoilwtico       21384 non-null  float64       \n 10  holidays_locale  1782 non-null   object        \n 11  transferred      1782 non-null   object        \ndtypes: datetime64[ns](1), float64(1), int64(4), object(6)\nmemory usage: 2.6+ MB\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# check the missing values\nprint(\"---missing value---\")\nprint(train.isnull().sum())\n\nprint(\"\\n---unique value---\")\nfor col in train:\n    print(f\"{col}:{train[col].nunique()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T04:32:38.010538Z","iopub.execute_input":"2025-08-05T04:32:38.010763Z","iopub.status.idle":"2025-08-05T04:32:39.887730Z","shell.execute_reply.started":"2025-08-05T04:32:38.010745Z","shell.execute_reply":"2025-08-05T04:32:39.886722Z"}},"outputs":[{"name":"stdout","text":"---missing value---\nid                       0\ndate                     0\nstore_nbr                0\nfamily                   0\nsales                    0\nonpromotion              0\ncity                     0\nstate                    0\ntype                     0\ncluster                  0\ntransactions        249117\ndcoilwtico          955152\nholidays_locale    2551824\ntransferred        2551824\ndtype: int64\n\n---unique value---\nid:3000888\ndate:1684\nstore_nbr:54\nfamily:33\nsales:379610\nonpromotion:362\ncity:22\nstate:16\ntype:5\ncluster:17\ntransactions:4993\ndcoilwtico:994\nholidays_locale:3\ntransferred:2\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"#fill in the missing value\ntrain['holidays_locale'] = train['holidays_locale'].fillna(False)\ntrain['transferred'] = train['transferred'].fillna(False)\ntrain['transactions'] = train.groupby('store_nbr')['transactions'].transform(lambda x: x.fillna(x.median()))\ntrain['dcoilwtico'] = train['dcoilwtico'].interpolate(method='linear')\ntrain['dcoilwtico'] = train['dcoilwtico'].fillna(method='ffill').fillna(method='bfill')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T04:32:39.888668Z","iopub.execute_input":"2025-08-05T04:32:39.888913Z","iopub.status.idle":"2025-08-05T04:32:41.076802Z","shell.execute_reply.started":"2025-08-05T04:32:39.888894Z","shell.execute_reply":"2025-08-05T04:32:41.075585Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/1759415756.py:3: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  train['transferred'] = train['transferred'].fillna(False)\n/tmp/ipykernel_36/1759415756.py:6: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  train['dcoilwtico'] = train['dcoilwtico'].fillna(method='ffill').fillna(method='bfill')\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# check the missing values\nprint(\"---missing value---\")\nprint(train.isnull().sum())\n\nprint(\"\\n---unique value---\")\nfor col in train:\n    print(f\"{col}:{train[col].nunique()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T04:32:41.077811Z","iopub.execute_input":"2025-08-05T04:32:41.078183Z","iopub.status.idle":"2025-08-05T04:32:42.837226Z","shell.execute_reply.started":"2025-08-05T04:32:41.078154Z","shell.execute_reply":"2025-08-05T04:32:42.836412Z"}},"outputs":[{"name":"stdout","text":"---missing value---\nid                 0\ndate               0\nstore_nbr          0\nfamily             0\nsales              0\nonpromotion        0\ncity               0\nstate              0\ntype               0\ncluster            0\ntransactions       0\ndcoilwtico         0\nholidays_locale    0\ntransferred        0\ndtype: int64\n\n---unique value---\nid:3000888\ndate:1684\nstore_nbr:54\nfamily:33\nsales:379610\nonpromotion:362\ncity:22\nstate:16\ntype:5\ncluster:17\ntransactions:5001\ndcoilwtico:933305\nholidays_locale:4\ntransferred:2\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"#extract temporal feature\ntrain['year'] = train['date'].dt.year\ntrain['month'] = train['date'].dt.month\ntrain['day'] = train['date'].dt.day\ntrain['dayofweek'] = train['date'].dt.dayofweek\ntrain['weekofyear'] = train['date'].dt.isocalendar().week.astype(int)\ntrain['is_weekend'] = train['dayofweek'].isin([5, 6]).astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T04:32:42.839262Z","iopub.execute_input":"2025-08-05T04:32:42.839591Z","iopub.status.idle":"2025-08-05T04:32:43.330097Z","shell.execute_reply.started":"2025-08-05T04:32:42.839567Z","shell.execute_reply":"2025-08-05T04:32:43.329370Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"#extract temporal feature\ntrain['year'] = train['date'].dt.year\ntrain['month'] = train['date'].dt.month\ntrain['day'] = train['date'].dt.day\ntrain['dayofweek'] = train['date'].dt.dayofweek\ntrain['weekofyear'] = train['date'].dt.isocalendar().week.astype(int)\ntrain['is_weekend'] = train['dayofweek'].isin([5, 6]).astype(int)\n\n\n#adjust the order of dataset\ntrain_order = [\n    'id', 'date','year','month','day','dayofweek','weekofyear','is_weekend', 'holidays_locale', 'transferred', \n    'dcoilwtico',\n    'store_nbr', 'city', 'state', 'type', 'cluster',\n    'onpromotion', 'family', 'transactions','sales'\n]\n\ntest_order = [\n    'id', 'date','year','month','day','dayofweek','weekofyear','is_weekend','holidays_locale', 'transferred', \n    'dcoilwtico',\n    'store_nbr',  'city', 'state', 'type', 'cluster',\n   'onpromotion', 'family'\n]\n\ntrain = train[train_order]\ntest = test[test_order]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T04:32:43.330864Z","iopub.execute_input":"2025-08-05T04:32:43.331099Z","iopub.status.idle":"2025-08-05T04:32:44.234231Z","shell.execute_reply.started":"2025-08-05T04:32:43.331078Z","shell.execute_reply":"2025-08-05T04:32:44.233187Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3920537293.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_order\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_order\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6252\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6254\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: \"['year', 'month', 'day', 'dayofweek', 'weekofyear', 'is_weekend'] not in index\""],"ename":"KeyError","evalue":"\"['year', 'month', 'day', 'dayofweek', 'weekofyear', 'is_weekend'] not in index\"","output_type":"error"}],"execution_count":8},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\n\n# splite train set and test setï¼Œdependent and independent variables\nX_train = train[train['date'] < '2017-01-01'].drop(columns=['sales', 'date', 'id'])\ny_train = train[train['date'] < '2017-01-01']['sales']\nX_val = train[train['date'] >= '2017-01-01'].drop(columns=['sales', 'date', 'id'])\ny_val = train[train['date'] >= '2017-01-01']['sales']\n\n\n# split categorical and numerical columns\ncat_cols = ['store_nbr', 'family', 'city', 'state', 'type', 'cluster', 'holidays_locale', 'transferred']\nfor col in cat_cols:\n    le = LabelEncoder()\n    train[col] = le.fit_transform(train[col].astype(str))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T04:33:15.210714Z","iopub.execute_input":"2025-08-05T04:33:15.210988Z","iopub.status.idle":"2025-08-05T04:33:24.626381Z","shell.execute_reply.started":"2025-08-05T04:33:15.210970Z","shell.execute_reply":"2025-08-05T04:33:24.625650Z"}},"outputs":[],"execution_count":9}]}