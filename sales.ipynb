{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe2a946f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-26T02:05:32.504603Z",
     "iopub.status.busy": "2025-08-26T02:05:32.504263Z",
     "iopub.status.idle": "2025-08-26T02:05:34.584735Z",
     "shell.execute_reply": "2025-08-26T02:05:34.583382Z"
    },
    "papermill": {
     "duration": 2.087003,
     "end_time": "2025-08-26T02:05:34.586425",
     "exception": false,
     "start_time": "2025-08-26T02:05:32.499422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/store-sales-time-series-forecasting/oil.csv\n",
      "/kaggle/input/store-sales-time-series-forecasting/sample_submission.csv\n",
      "/kaggle/input/store-sales-time-series-forecasting/holidays_events.csv\n",
      "/kaggle/input/store-sales-time-series-forecasting/stores.csv\n",
      "/kaggle/input/store-sales-time-series-forecasting/train.csv\n",
      "/kaggle/input/store-sales-time-series-forecasting/test.csv\n",
      "/kaggle/input/store-sales-time-series-forecasting/transactions.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ec533c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T02:05:34.594536Z",
     "iopub.status.busy": "2025-08-26T02:05:34.593978Z",
     "iopub.status.idle": "2025-08-26T02:05:38.101200Z",
     "shell.execute_reply": "2025-08-26T02:05:38.100069Z"
    },
    "papermill": {
     "duration": 3.513137,
     "end_time": "2025-08-26T02:05:38.103061",
     "exception": false,
     "start_time": "2025-08-26T02:05:34.589924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# input dataset\n",
    "train = pd.read_csv(\"/kaggle/input/store-sales-time-series-forecasting/train.csv\")\n",
    "test = pd.read_csv(\"/kaggle/input/store-sales-time-series-forecasting/test.csv\")\n",
    "stores = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/stores.csv')\n",
    "holidays = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/holidays_events.csv', parse_dates=['date'])\n",
    "oil = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/oil.csv', parse_dates=['date'])\n",
    "transactions = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/transactions.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3024aae3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T02:05:38.112332Z",
     "iopub.status.busy": "2025-08-26T02:05:38.111073Z",
     "iopub.status.idle": "2025-08-26T02:05:41.382118Z",
     "shell.execute_reply": "2025-08-26T02:05:41.380541Z"
    },
    "papermill": {
     "duration": 3.277569,
     "end_time": "2025-08-26T02:05:41.384076",
     "exception": false,
     "start_time": "2025-08-26T02:05:38.106507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3054348 entries, 0 to 3054347\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Dtype         \n",
      "---  ------           -----         \n",
      " 0   id               int64         \n",
      " 1   date             datetime64[ns]\n",
      " 2   store_nbr        int64         \n",
      " 3   family           object        \n",
      " 4   sales            float64       \n",
      " 5   onpromotion      int64         \n",
      " 6   city             object        \n",
      " 7   state            object        \n",
      " 8   type             object        \n",
      " 9   cluster          int64         \n",
      " 10  transactions     float64       \n",
      " 11  dcoilwtico       float64       \n",
      " 12  holidays_locale  object        \n",
      " 13  transferred      object        \n",
      "dtypes: datetime64[ns](1), float64(3), int64(4), object(6)\n",
      "memory usage: 326.2+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28512 entries, 0 to 28511\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   id               28512 non-null  int64         \n",
      " 1   date             28512 non-null  datetime64[ns]\n",
      " 2   store_nbr        28512 non-null  int64         \n",
      " 3   family           28512 non-null  object        \n",
      " 4   onpromotion      28512 non-null  int64         \n",
      " 5   city             28512 non-null  object        \n",
      " 6   state            28512 non-null  object        \n",
      " 7   type             28512 non-null  object        \n",
      " 8   cluster          28512 non-null  int64         \n",
      " 9   transactions     0 non-null      float64       \n",
      " 10  dcoilwtico       21384 non-null  float64       \n",
      " 11  holidays_locale  1782 non-null   object        \n",
      " 12  transferred      1782 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(2), int64(4), object(6)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# adjust date formats\n",
    "train['date'] = pd.to_datetime(train['date'])\n",
    "test['date'] = pd.to_datetime(test['date'])\n",
    "transactions['date'] = pd.to_datetime(transactions['date'])\n",
    "holidays['date'] = pd.to_datetime(holidays['date'])\n",
    "oil['date'] = pd.to_datetime(oil['date'])\n",
    "\n",
    "# merge the dataset\n",
    "train = train.merge(stores, on='store_nbr', how='left')\n",
    "test = test.merge(stores, on='store_nbr', how='left')\n",
    "\n",
    "train = train.merge(transactions, on=['date', 'store_nbr'], how='left')\n",
    "test = test.merge(transactions, on=['date', 'store_nbr'], how='left')\n",
    "\n",
    "train = train.merge(oil, on='date', how='left')\n",
    "test = test.merge(oil, on='date', how='left')\n",
    "\n",
    "holidays = holidays[['date', 'locale', 'transferred']].rename(columns={'locale': 'holidays_locale'})\n",
    "train = train.merge(holidays, on='date', how='left', suffixes=('', '_holiday'))\n",
    "test = test.merge(holidays, on='date', how='left', suffixes=('', '_holiday'))\n",
    "\n",
    "train.info()\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a08ae46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T02:05:41.393330Z",
     "iopub.status.busy": "2025-08-26T02:05:41.391985Z",
     "iopub.status.idle": "2025-08-26T02:05:43.375296Z",
     "shell.execute_reply": "2025-08-26T02:05:43.374257Z"
    },
    "papermill": {
     "duration": 1.989645,
     "end_time": "2025-08-26T02:05:43.377107",
     "exception": false,
     "start_time": "2025-08-26T02:05:41.387462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---missing value---\n",
      "id                       0\n",
      "date                     0\n",
      "store_nbr                0\n",
      "family                   0\n",
      "sales                    0\n",
      "onpromotion              0\n",
      "city                     0\n",
      "state                    0\n",
      "type                     0\n",
      "cluster                  0\n",
      "transactions        249117\n",
      "dcoilwtico          955152\n",
      "holidays_locale    2551824\n",
      "transferred        2551824\n",
      "dtype: int64\n",
      "id                     0\n",
      "date                   0\n",
      "store_nbr              0\n",
      "family                 0\n",
      "onpromotion            0\n",
      "city                   0\n",
      "state                  0\n",
      "type                   0\n",
      "cluster                0\n",
      "transactions       28512\n",
      "dcoilwtico          7128\n",
      "holidays_locale    26730\n",
      "transferred        26730\n",
      "dtype: int64\n",
      "\n",
      "---unique value---\n",
      "id:3000888\n",
      "date:1684\n",
      "store_nbr:54\n",
      "family:33\n",
      "sales:379610\n",
      "onpromotion:362\n",
      "city:22\n",
      "state:16\n",
      "type:5\n",
      "cluster:17\n",
      "transactions:4993\n",
      "dcoilwtico:994\n",
      "holidays_locale:3\n",
      "transferred:2\n"
     ]
    }
   ],
   "source": [
    "# check the missing values\n",
    "print(\"---missing value---\")\n",
    "print(train.isnull().sum())\n",
    "print(test.isnull().sum())\n",
    "\n",
    "print(\"\\n---unique value---\")\n",
    "for col in train:\n",
    "    print(f\"{col}:{train[col].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4df4ecba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T02:05:43.386083Z",
     "iopub.status.busy": "2025-08-26T02:05:43.385679Z",
     "iopub.status.idle": "2025-08-26T02:05:44.724996Z",
     "shell.execute_reply": "2025-08-26T02:05:44.723921Z"
    },
    "papermill": {
     "duration": 1.346664,
     "end_time": "2025-08-26T02:05:44.727349",
     "exception": false,
     "start_time": "2025-08-26T02:05:43.380685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/2010465726.py:5: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train['transferred'] = train['transferred'].fillna(False)\n",
      "/tmp/ipykernel_13/2010465726.py:6: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test['transferred'] = test['transferred'].fillna(False)\n",
      "/tmp/ipykernel_13/2010465726.py:14: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train['dcoilwtico'] = train['dcoilwtico'].fillna(method='ffill').fillna(method='bfill')\n",
      "/tmp/ipykernel_13/2010465726.py:15: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  test['dcoilwtico'] = test['dcoilwtico'].fillna(method='ffill').fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "#fill in the missing value\n",
    "train['holidays_locale'] = train['holidays_locale'].fillna(False)\n",
    "test['holidays_locale'] = test['holidays_locale'].fillna(False)\n",
    "\n",
    "train['transferred'] = train['transferred'].fillna(False)\n",
    "test['transferred'] = test['transferred'].fillna(False)\n",
    "\n",
    "train['transactions'] = train.groupby('store_nbr')['transactions'].transform(lambda x: x.fillna(x.median()))\n",
    "store_medians = train.groupby('store_nbr')['transactions'].median()\n",
    "test['transactions'] = test['store_nbr'].map(store_medians)\n",
    "\n",
    "train['dcoilwtico'] = train['dcoilwtico'].interpolate(method='linear')\n",
    "test['dcoilwtico'] = test['dcoilwtico'].interpolate(method='linear')\n",
    "train['dcoilwtico'] = train['dcoilwtico'].fillna(method='ffill').fillna(method='bfill')\n",
    "test['dcoilwtico'] = test['dcoilwtico'].fillna(method='ffill').fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1b31ba7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T02:05:44.737093Z",
     "iopub.status.busy": "2025-08-26T02:05:44.736753Z",
     "iopub.status.idle": "2025-08-26T02:05:46.635138Z",
     "shell.execute_reply": "2025-08-26T02:05:46.633993Z"
    },
    "papermill": {
     "duration": 1.905349,
     "end_time": "2025-08-26T02:05:46.636714",
     "exception": false,
     "start_time": "2025-08-26T02:05:44.731365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---missing value---\n",
      "id                 0\n",
      "date               0\n",
      "store_nbr          0\n",
      "family             0\n",
      "sales              0\n",
      "onpromotion        0\n",
      "city               0\n",
      "state              0\n",
      "type               0\n",
      "cluster            0\n",
      "transactions       0\n",
      "dcoilwtico         0\n",
      "holidays_locale    0\n",
      "transferred        0\n",
      "dtype: int64\n",
      "id                 0\n",
      "date               0\n",
      "store_nbr          0\n",
      "family             0\n",
      "onpromotion        0\n",
      "city               0\n",
      "state              0\n",
      "type               0\n",
      "cluster            0\n",
      "transactions       0\n",
      "dcoilwtico         0\n",
      "holidays_locale    0\n",
      "transferred        0\n",
      "dtype: int64\n",
      "\n",
      "---unique value---\n",
      "id:3000888\n",
      "date:1684\n",
      "store_nbr:54\n",
      "family:33\n",
      "sales:379610\n",
      "onpromotion:362\n",
      "city:22\n",
      "state:16\n",
      "type:5\n",
      "cluster:17\n",
      "transactions:5001\n",
      "dcoilwtico:933305\n",
      "holidays_locale:4\n",
      "transferred:2\n"
     ]
    }
   ],
   "source": [
    "# check the missing values\n",
    "print(\"---missing value---\")\n",
    "print(train.isnull().sum())\n",
    "print(test.isnull().sum())\n",
    "\n",
    "print(\"\\n---unique value---\")\n",
    "for col in train:\n",
    "    print(f\"{col}:{train[col].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e507ee0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T02:05:46.645600Z",
     "iopub.status.busy": "2025-08-26T02:05:46.645245Z",
     "iopub.status.idle": "2025-08-26T02:05:47.198922Z",
     "shell.execute_reply": "2025-08-26T02:05:47.197858Z"
    },
    "papermill": {
     "duration": 0.560199,
     "end_time": "2025-08-26T02:05:47.200758",
     "exception": false,
     "start_time": "2025-08-26T02:05:46.640559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#extract temporal feature\n",
    "train['year'] = train['date'].dt.year\n",
    "train['month'] = train['date'].dt.month\n",
    "train['day'] = train['date'].dt.day\n",
    "train['dayofweek'] = train['date'].dt.dayofweek\n",
    "train['weekofyear'] = train['date'].dt.isocalendar().week.astype(int)\n",
    "train['is_weekend'] = train['dayofweek'].isin([5, 6]).astype(int)\n",
    "\n",
    "test['year'] = test['date'].dt.year\n",
    "test['month'] = test['date'].dt.month\n",
    "test['day'] = test['date'].dt.day\n",
    "test['dayofweek'] = test['date'].dt.dayofweek\n",
    "test['weekofyear'] = test['date'].dt.isocalendar().week.astype(int)\n",
    "test['is_weekend'] = test['dayofweek'].isin([5, 6]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15156c42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T02:05:47.209527Z",
     "iopub.status.busy": "2025-08-26T02:05:47.209145Z",
     "iopub.status.idle": "2025-08-26T02:05:47.590371Z",
     "shell.execute_reply": "2025-08-26T02:05:47.589119Z"
    },
    "papermill": {
     "duration": 0.387672,
     "end_time": "2025-08-26T02:05:47.592276",
     "exception": false,
     "start_time": "2025-08-26T02:05:47.204604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#adjust the order of dataset\n",
    "train_order = [\n",
    "    'id', 'date','year','month','day','dayofweek','weekofyear','is_weekend', 'holidays_locale', 'transferred', \n",
    "    'dcoilwtico',\n",
    "    'store_nbr', 'city', 'state', 'type', 'cluster',\n",
    "    'onpromotion', 'family', 'transactions','sales'\n",
    "]\n",
    "\n",
    "test_order = [\n",
    "    'id', 'date','year','month','day','dayofweek','weekofyear','is_weekend','holidays_locale', 'transferred', \n",
    "    'dcoilwtico',\n",
    "    'store_nbr',  'city', 'state', 'type', 'cluster',\n",
    "   'onpromotion', 'family', 'transactions'\n",
    "]\n",
    "\n",
    "train = train[train_order]\n",
    "test = test[test_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "974d5b77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T02:05:47.601740Z",
     "iopub.status.busy": "2025-08-26T02:05:47.601436Z",
     "iopub.status.idle": "2025-08-26T02:06:08.751026Z",
     "shell.execute_reply": "2025-08-26T02:06:08.750016Z"
    },
    "papermill": {
     "duration": 21.156801,
     "end_time": "2025-08-26T02:06:08.752782",
     "exception": false,
     "start_time": "2025-08-26T02:05:47.595981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2642706 entries, 0 to 2642705\n",
      "Data columns (total 17 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   year             int32  \n",
      " 1   month            int32  \n",
      " 2   day              int32  \n",
      " 3   dayofweek        int32  \n",
      " 4   weekofyear       int64  \n",
      " 5   is_weekend       int64  \n",
      " 6   holidays_locale  int64  \n",
      " 7   transferred      int64  \n",
      " 8   dcoilwtico       float64\n",
      " 9   store_nbr        int64  \n",
      " 10  city             int64  \n",
      " 11  state            int64  \n",
      " 12  type             int64  \n",
      " 13  cluster          int64  \n",
      " 14  onpromotion      int64  \n",
      " 15  family           int64  \n",
      " 16  transactions     float64\n",
      "dtypes: float64(2), int32(4), int64(11)\n",
      "memory usage: 322.6 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 411642 entries, 2642706 to 3054347\n",
      "Data columns (total 17 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   year             411642 non-null  int32  \n",
      " 1   month            411642 non-null  int32  \n",
      " 2   day              411642 non-null  int32  \n",
      " 3   dayofweek        411642 non-null  int32  \n",
      " 4   weekofyear       411642 non-null  int64  \n",
      " 5   is_weekend       411642 non-null  int64  \n",
      " 6   holidays_locale  411642 non-null  int64  \n",
      " 7   transferred      411642 non-null  int64  \n",
      " 8   dcoilwtico       411642 non-null  float64\n",
      " 9   store_nbr        411642 non-null  int64  \n",
      " 10  city             411642 non-null  int64  \n",
      " 11  state            411642 non-null  int64  \n",
      " 12  type             411642 non-null  int64  \n",
      " 13  cluster          411642 non-null  int64  \n",
      " 14  onpromotion      411642 non-null  int64  \n",
      " 15  family           411642 non-null  int64  \n",
      " 16  transactions     411642 non-null  float64\n",
      "dtypes: float64(2), int32(4), int64(11)\n",
      "memory usage: 50.2 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28512 entries, 0 to 28511\n",
      "Data columns (total 19 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   id               28512 non-null  int64         \n",
      " 1   date             28512 non-null  datetime64[ns]\n",
      " 2   year             28512 non-null  int32         \n",
      " 3   month            28512 non-null  int32         \n",
      " 4   day              28512 non-null  int32         \n",
      " 5   dayofweek        28512 non-null  int32         \n",
      " 6   weekofyear       28512 non-null  int64         \n",
      " 7   is_weekend       28512 non-null  int64         \n",
      " 8   holidays_locale  28512 non-null  int64         \n",
      " 9   transferred      28512 non-null  int64         \n",
      " 10  dcoilwtico       28512 non-null  float64       \n",
      " 11  store_nbr        28512 non-null  int64         \n",
      " 12  city             28512 non-null  int64         \n",
      " 13  state            28512 non-null  int64         \n",
      " 14  type             28512 non-null  int64         \n",
      " 15  cluster          28512 non-null  int64         \n",
      " 16  onpromotion      28512 non-null  int64         \n",
      " 17  family           28512 non-null  int64         \n",
      " 18  transactions     28512 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(2), int32(4), int64(12)\n",
      "memory usage: 3.7 MB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error\n",
    "import lightgbm as lgb\n",
    "\n",
    "# split categorical and numerical columns\n",
    "cat_cols = ['store_nbr', 'family', 'city', 'state', 'type', 'cluster', 'holidays_locale', 'transferred']\n",
    "encoders = {}\n",
    "\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    all_values = pd.concat([train[col], test[col]], axis=0).astype(str)\n",
    "    le.fit(all_values)\n",
    "    encoders[col] = le\n",
    "    train[col] = le.transform(train[col].astype(str))\n",
    "    test[col] = le.transform(test[col].astype(str))\n",
    "    \n",
    "# splite train set and validation set，dependent and independent variables\n",
    "X_train = train[train['date'] < '2017-01-01'].drop(columns=['sales', 'date', 'id'])\n",
    "y_train = train[train['date'] < '2017-01-01']['sales']\n",
    "X_val = train[train['date'] >= '2017-01-01'].drop(columns=['sales', 'date', 'id'])\n",
    "y_val = train[train['date'] >= '2017-01-01']['sales']\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "\n",
    "X_train.info()\n",
    "X_val.info()\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eae8e4ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T02:06:08.762889Z",
     "iopub.status.busy": "2025-08-26T02:06:08.761964Z",
     "iopub.status.idle": "2025-08-26T02:07:57.049375Z",
     "shell.execute_reply": "2025-08-26T02:07:57.048001Z"
    },
    "papermill": {
     "duration": 108.294179,
     "end_time": "2025-08-26T02:07:57.051031",
     "exception": false,
     "start_time": "2025-08-26T02:06:08.756852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 321.671\tvalid's rmse: 375.773\n",
      "[200]\ttrain's rmse: 273.641\tvalid's rmse: 335.942\n",
      "[300]\ttrain's rmse: 250.873\tvalid's rmse: 325.056\n",
      "[400]\ttrain's rmse: 236.794\tvalid's rmse: 319.129\n",
      "[500]\ttrain's rmse: 226.507\tvalid's rmse: 318.81\n",
      "[600]\ttrain's rmse: 218.462\tvalid's rmse: 317.416\n",
      "[700]\ttrain's rmse: 211.347\tvalid's rmse: 316.762\n",
      "[800]\ttrain's rmse: 205.863\tvalid's rmse: 317.114\n",
      "Early stopping, best iteration is:\n",
      "[705]\ttrain's rmse: 211.039\tvalid's rmse: 316.6\n",
      "Validation RMSE: 316.5996\n",
      "Validation RMSLE: 1.4080\n",
      "提交文件已生成 submission.csv\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 64,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=2000,\n",
    "    valid_sets=[train_data, val_data],\n",
    "    valid_names=['train', 'valid'],\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=100),\n",
    "        lgb.log_evaluation(period=100)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 验证集预测\n",
    "y_val_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "\n",
    "rmse = mean_squared_error(y_val, y_val_pred, squared=False)\n",
    "rmsle = np.sqrt(mean_squared_log_error(y_val, np.maximum(y_val_pred, 0)))\n",
    "\n",
    "print(f\"Validation RMSE: {rmse:.4f}\")\n",
    "print(f\"Validation RMSLE: {rmsle:.4f}\")\n",
    "\n",
    "# 在 test 上预测\n",
    "X_test = test.drop(columns=['date','id'])\n",
    "y_test_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "\n",
    "# 生成提交文件\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'sales': np.maximum(y_test_pred, 0)   # 销量不能为负\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"提交文件已生成 submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 2887556,
     "sourceId": 29781,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 152.598666,
   "end_time": "2025-08-26T02:07:58.180720",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-26T02:05:25.582054",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
