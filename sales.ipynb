{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":29781,"databundleVersionId":2887556,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-25T07:33:36.497478Z","iopub.execute_input":"2025-08-25T07:33:36.497981Z","iopub.status.idle":"2025-08-25T07:33:36.514655Z","shell.execute_reply.started":"2025-08-25T07:33:36.497949Z","shell.execute_reply":"2025-08-25T07:33:36.512597Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/store-sales-time-series-forecasting/oil.csv\n/kaggle/input/store-sales-time-series-forecasting/sample_submission.csv\n/kaggle/input/store-sales-time-series-forecasting/holidays_events.csv\n/kaggle/input/store-sales-time-series-forecasting/stores.csv\n/kaggle/input/store-sales-time-series-forecasting/train.csv\n/kaggle/input/store-sales-time-series-forecasting/test.csv\n/kaggle/input/store-sales-time-series-forecasting/transactions.csv\n","output_type":"stream"}],"execution_count":74},{"cell_type":"code","source":"# input dataset\ntrain = pd.read_csv(\"/kaggle/input/store-sales-time-series-forecasting/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/store-sales-time-series-forecasting/test.csv\")\nstores = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/stores.csv')\nholidays = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/holidays_events.csv', parse_dates=['date'])\noil = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/oil.csv', parse_dates=['date'])\ntransactions = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/transactions.csv', parse_dates=['date'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T07:33:36.517167Z","iopub.execute_input":"2025-08-25T07:33:36.518319Z","iopub.status.idle":"2025-08-25T07:33:38.334702Z","shell.execute_reply.started":"2025-08-25T07:33:36.518255Z","shell.execute_reply":"2025-08-25T07:33:38.333768Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"# adjust date formats\ntrain['date'] = pd.to_datetime(train['date'])\ntest['date'] = pd.to_datetime(test['date'])\ntransactions['date'] = pd.to_datetime(transactions['date'])\nholidays['date'] = pd.to_datetime(holidays['date'])\noil['date'] = pd.to_datetime(oil['date'])\n\n# merge the dataset\ntrain = train.merge(stores, on='store_nbr', how='left')\ntest = test.merge(stores, on='store_nbr', how='left')\n\ntrain = train.merge(transactions, on=['date', 'store_nbr'], how='left')\ntest = test.merge(transactions, on=['date', 'store_nbr'], how='left')\n\ntrain = train.merge(oil, on='date', how='left')\ntest = test.merge(oil, on='date', how='left')\n\nholidays = holidays[['date', 'locale', 'transferred']].rename(columns={'locale': 'holidays_locale'})\ntrain = train.merge(holidays, on='date', how='left', suffixes=('', '_holiday'))\ntest = test.merge(holidays, on='date', how='left', suffixes=('', '_holiday'))\n\ntrain.info()\ntest.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T07:33:38.335588Z","iopub.execute_input":"2025-08-25T07:33:38.335911Z","iopub.status.idle":"2025-08-25T07:33:40.702816Z","shell.execute_reply.started":"2025-08-25T07:33:38.335890Z","shell.execute_reply":"2025-08-25T07:33:40.701719Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3054348 entries, 0 to 3054347\nData columns (total 14 columns):\n #   Column           Dtype         \n---  ------           -----         \n 0   id               int64         \n 1   date             datetime64[ns]\n 2   store_nbr        int64         \n 3   family           object        \n 4   sales            float64       \n 5   onpromotion      int64         \n 6   city             object        \n 7   state            object        \n 8   type             object        \n 9   cluster          int64         \n 10  transactions     float64       \n 11  dcoilwtico       float64       \n 12  holidays_locale  object        \n 13  transferred      object        \ndtypes: datetime64[ns](1), float64(3), int64(4), object(6)\nmemory usage: 326.2+ MB\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 28512 entries, 0 to 28511\nData columns (total 13 columns):\n #   Column           Non-Null Count  Dtype         \n---  ------           --------------  -----         \n 0   id               28512 non-null  int64         \n 1   date             28512 non-null  datetime64[ns]\n 2   store_nbr        28512 non-null  int64         \n 3   family           28512 non-null  object        \n 4   onpromotion      28512 non-null  int64         \n 5   city             28512 non-null  object        \n 6   state            28512 non-null  object        \n 7   type             28512 non-null  object        \n 8   cluster          28512 non-null  int64         \n 9   transactions     0 non-null      float64       \n 10  dcoilwtico       21384 non-null  float64       \n 11  holidays_locale  1782 non-null   object        \n 12  transferred      1782 non-null   object        \ndtypes: datetime64[ns](1), float64(2), int64(4), object(6)\nmemory usage: 2.8+ MB\n","output_type":"stream"}],"execution_count":76},{"cell_type":"code","source":"# check the missing values\nprint(\"---missing value---\")\nprint(train.isnull().sum())\n\nprint(\"\\n---unique value---\")\nfor col in train:\n    print(f\"{col}:{train[col].nunique()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T07:33:40.704086Z","iopub.execute_input":"2025-08-25T07:33:40.704395Z","iopub.status.idle":"2025-08-25T07:33:42.639556Z","shell.execute_reply.started":"2025-08-25T07:33:40.704363Z","shell.execute_reply":"2025-08-25T07:33:42.638492Z"}},"outputs":[{"name":"stdout","text":"---missing value---\nid                       0\ndate                     0\nstore_nbr                0\nfamily                   0\nsales                    0\nonpromotion              0\ncity                     0\nstate                    0\ntype                     0\ncluster                  0\ntransactions        249117\ndcoilwtico          955152\nholidays_locale    2551824\ntransferred        2551824\ndtype: int64\n\n---unique value---\nid:3000888\ndate:1684\nstore_nbr:54\nfamily:33\nsales:379610\nonpromotion:362\ncity:22\nstate:16\ntype:5\ncluster:17\ntransactions:4993\ndcoilwtico:994\nholidays_locale:3\ntransferred:2\n","output_type":"stream"}],"execution_count":77},{"cell_type":"code","source":"#fill in the missing value\ntrain['holidays_locale'] = train['holidays_locale'].fillna(False)\ntrain['transferred'] = train['transferred'].fillna(False)\ntrain['transactions'] = train.groupby('store_nbr')['transactions'].transform(lambda x: x.fillna(x.median()))\ntrain['dcoilwtico'] = train['dcoilwtico'].interpolate(method='linear')\ntrain['dcoilwtico'] = train['dcoilwtico'].fillna(method='ffill').fillna(method='bfill')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T07:33:42.641914Z","iopub.execute_input":"2025-08-25T07:33:42.642171Z","iopub.status.idle":"2025-08-25T07:33:43.873263Z","shell.execute_reply.started":"2025-08-25T07:33:42.642152Z","shell.execute_reply":"2025-08-25T07:33:43.872159Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/1759415756.py:3: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  train['transferred'] = train['transferred'].fillna(False)\n/tmp/ipykernel_36/1759415756.py:6: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  train['dcoilwtico'] = train['dcoilwtico'].fillna(method='ffill').fillna(method='bfill')\n","output_type":"stream"}],"execution_count":78},{"cell_type":"code","source":"# check the missing values\nprint(\"---missing value---\")\nprint(train.isnull().sum())\n\nprint(\"\\n---unique value---\")\nfor col in train:\n    print(f\"{col}:{train[col].nunique()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T07:33:43.874244Z","iopub.execute_input":"2025-08-25T07:33:43.874545Z","iopub.status.idle":"2025-08-25T07:33:45.757800Z","shell.execute_reply.started":"2025-08-25T07:33:43.874519Z","shell.execute_reply":"2025-08-25T07:33:45.756838Z"}},"outputs":[{"name":"stdout","text":"---missing value---\nid                 0\ndate               0\nstore_nbr          0\nfamily             0\nsales              0\nonpromotion        0\ncity               0\nstate              0\ntype               0\ncluster            0\ntransactions       0\ndcoilwtico         0\nholidays_locale    0\ntransferred        0\ndtype: int64\n\n---unique value---\nid:3000888\ndate:1684\nstore_nbr:54\nfamily:33\nsales:379610\nonpromotion:362\ncity:22\nstate:16\ntype:5\ncluster:17\ntransactions:5001\ndcoilwtico:933305\nholidays_locale:4\ntransferred:2\n","output_type":"stream"}],"execution_count":79},{"cell_type":"code","source":"#extract temporal feature\ntrain['year'] = train['date'].dt.year\ntrain['month'] = train['date'].dt.month\ntrain['day'] = train['date'].dt.day\ntrain['dayofweek'] = train['date'].dt.dayofweek\ntrain['weekofyear'] = train['date'].dt.isocalendar().week.astype(int)\ntrain['is_weekend'] = train['dayofweek'].isin([5, 6]).astype(int)\n\ntest['year'] = test['date'].dt.year\ntest['month'] = test['date'].dt.month\ntest['day'] = test['date'].dt.day\ntest['dayofweek'] = test['date'].dt.dayofweek\ntest['weekofyear'] = test['date'].dt.isocalendar().week.astype(int)\ntest['is_weekend'] = test['dayofweek'].isin([5, 6]).astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T07:33:45.758921Z","iopub.execute_input":"2025-08-25T07:33:45.759569Z","iopub.status.idle":"2025-08-25T07:33:46.295378Z","shell.execute_reply.started":"2025-08-25T07:33:45.759534Z","shell.execute_reply":"2025-08-25T07:33:46.294328Z"}},"outputs":[],"execution_count":80},{"cell_type":"code","source":"#adjust the order of dataset\ntrain_order = [\n    'id', 'date','year','month','day','dayofweek','weekofyear','is_weekend', 'holidays_locale', 'transferred', \n    'dcoilwtico',\n    'store_nbr', 'city', 'state', 'type', 'cluster',\n    'onpromotion', 'family', 'transactions','sales'\n]\n\ntest_order = [\n    'id', 'date','year','month','day','dayofweek','weekofyear','is_weekend','holidays_locale', 'transferred', \n    'dcoilwtico',\n    'store_nbr',  'city', 'state', 'type', 'cluster',\n   'onpromotion', 'family'\n]\n\ntrain = train[train_order]\ntest = test[test_order]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T07:33:46.296368Z","iopub.execute_input":"2025-08-25T07:33:46.296743Z","iopub.status.idle":"2025-08-25T07:33:46.565519Z","shell.execute_reply.started":"2025-08-25T07:33:46.296711Z","shell.execute_reply":"2025-08-25T07:33:46.564457Z"}},"outputs":[],"execution_count":81},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import mean_squared_log_error, mean_squared_error\nimport lightgbm as lgb\n\n# splite train set and validation set，dependent and independent variables\nX_train = train[train['date'] < '2017-01-01'].drop(columns=['sales', 'date', 'id'])\ny_train = train[train['date'] < '2017-01-01']['sales']\nX_val = train[train['date'] >= '2017-01-01'].drop(columns=['sales', 'date', 'id'])\ny_val = train[train['date'] >= '2017-01-01']['sales']\n\ntest = test.drop(columns=['id', 'date'])\n\n# split categorical and numerical columns\ncat_cols = ['store_nbr', 'family', 'city', 'state', 'type', 'cluster', 'holidays_locale', 'transferred']\nencoders = {}\n\nfor col in cat_cols:\n    le = LabelEncoder()\n    all_values = pd.concat([train[col], test[col]], axis=0).astype(str)\n    le.fit(all_values)\n    encoders[col] = le\n    train[col] = le.transform(train[col].astype(str))\n    test[col] = le.transform(test[col].astype(str))\n\n\ntrain_data = lgb.Dataset(X_train, label=y_train)\nval_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n\nX_train.info()\nX_val.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T07:33:46.566612Z","iopub.execute_input":"2025-08-25T07:33:46.566935Z","iopub.status.idle":"2025-08-25T07:33:59.506450Z","shell.execute_reply.started":"2025-08-25T07:33:46.566911Z","shell.execute_reply":"2025-08-25T07:33:59.505543Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 2642706 entries, 0 to 2642705\nData columns (total 17 columns):\n #   Column           Dtype  \n---  ------           -----  \n 0   year             int32  \n 1   month            int32  \n 2   day              int32  \n 3   dayofweek        int32  \n 4   weekofyear       int64  \n 5   is_weekend       int64  \n 6   holidays_locale  object \n 7   transferred      bool   \n 8   dcoilwtico       float64\n 9   store_nbr        int64  \n 10  city             object \n 11  state            object \n 12  type             object \n 13  cluster          int64  \n 14  onpromotion      int64  \n 15  family           object \n 16  transactions     float64\ndtypes: bool(1), float64(2), int32(4), int64(5), object(5)\nmemory usage: 305.0+ MB\n<class 'pandas.core.frame.DataFrame'>\nIndex: 411642 entries, 2642706 to 3054347\nData columns (total 17 columns):\n #   Column           Non-Null Count   Dtype  \n---  ------           --------------   -----  \n 0   year             411642 non-null  int32  \n 1   month            411642 non-null  int32  \n 2   day              411642 non-null  int32  \n 3   dayofweek        411642 non-null  int32  \n 4   weekofyear       411642 non-null  int64  \n 5   is_weekend       411642 non-null  int64  \n 6   holidays_locale  411642 non-null  object \n 7   transferred      411642 non-null  bool   \n 8   dcoilwtico       411642 non-null  float64\n 9   store_nbr        411642 non-null  int64  \n 10  city             411642 non-null  object \n 11  state            411642 non-null  object \n 12  type             411642 non-null  object \n 13  cluster          411642 non-null  int64  \n 14  onpromotion      411642 non-null  int64  \n 15  family           411642 non-null  object \n 16  transactions     411642 non-null  float64\ndtypes: bool(1), float64(2), int32(4), int64(5), object(5)\nmemory usage: 47.5+ MB\n","output_type":"stream"}],"execution_count":82},{"cell_type":"code","source":"test.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T07:33:59.507416Z","iopub.execute_input":"2025-08-25T07:33:59.507755Z","iopub.status.idle":"2025-08-25T07:33:59.521596Z","shell.execute_reply.started":"2025-08-25T07:33:59.507732Z","shell.execute_reply":"2025-08-25T07:33:59.520584Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 28512 entries, 0 to 28511\nData columns (total 16 columns):\n #   Column           Non-Null Count  Dtype  \n---  ------           --------------  -----  \n 0   year             28512 non-null  int32  \n 1   month            28512 non-null  int32  \n 2   day              28512 non-null  int32  \n 3   dayofweek        28512 non-null  int32  \n 4   weekofyear       28512 non-null  int64  \n 5   is_weekend       28512 non-null  int64  \n 6   holidays_locale  28512 non-null  int64  \n 7   transferred      28512 non-null  int64  \n 8   dcoilwtico       21384 non-null  float64\n 9   store_nbr        28512 non-null  int64  \n 10  city             28512 non-null  int64  \n 11  state            28512 non-null  int64  \n 12  type             28512 non-null  int64  \n 13  cluster          28512 non-null  int64  \n 14  onpromotion      28512 non-null  int64  \n 15  family           28512 non-null  int64  \ndtypes: float64(1), int32(4), int64(11)\nmemory usage: 3.0 MB\n","output_type":"stream"}],"execution_count":83},{"cell_type":"code","source":"params = {\n    'objective': 'regression',\n    'metric': 'rmse',\n    'boosting_type': 'gbdt',\n    'num_leaves': 64,\n    'learning_rate': 0.05,\n    'feature_fraction': 0.8,\n    'bagging_fraction': 0.8,\n    'bagging_freq': 5,\n    'verbose': -1\n}\n\n# ✅ 改用 callbacks 传 early_stopping\nmodel = lgb.train(\n    params,\n    train_data,\n    num_boost_round=2000,\n    valid_sets=[train_data, val_data],\n    valid_names=['train', 'valid'],\n    callbacks=[\n        lgb.early_stopping(stopping_rounds=100),\n        lgb.log_evaluation(period=100)\n    ]\n)\n\n# 验证集预测\ny_val_pred = model.predict(X_val, num_iteration=model.best_iteration)\n\nrmse = mean_squared_error(y_val, y_val_pred, squared=False)\nrmsle = np.sqrt(mean_squared_log_error(y_val, np.maximum(y_val_pred, 0)))\n\nprint(f\"Validation RMSE: {rmse:.4f}\")\nprint(f\"Validation RMSLE: {rmsle:.4f}\")\n\n# 7. 在 test 上预测\nX_test = test.drop(columns=['date','id'])\ny_test_pred = model.predict(X_test, num_iteration=model.best_iteration)\n\n# 8. 生成提交文件\nsubmission = pd.DataFrame({\n    'id': test['id'],\n    'sales': np.maximum(y_test_pred, 0)   # 销量不能为负\n})\n\nsubmission.to_csv('submission.csv', index=False)\nprint(\"✅ 提交文件已生成 submission.csv\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T07:33:59.522718Z","iopub.execute_input":"2025-08-25T07:33:59.523043Z","iopub.status.idle":"2025-08-25T07:33:59.532932Z","shell.execute_reply.started":"2025-08-25T07:33:59.523013Z","shell.execute_reply":"2025-08-25T07:33:59.531688Z"}},"outputs":[{"traceback":["\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_36/3965208228.py\"\u001b[0;36m, line \u001b[0;32m46\u001b[0m\n\u001b[0;31m    print(\"✅ 提交文件已生成 submission.csv\"\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"],"ename":"SyntaxError","evalue":"incomplete input (3965208228.py, line 46)","output_type":"error"}],"execution_count":84}]}