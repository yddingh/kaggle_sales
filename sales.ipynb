{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":29781,"databundleVersionId":2887556,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-28T07:08:07.372055Z","iopub.execute_input":"2025-07-28T07:08:07.372431Z","iopub.status.idle":"2025-07-28T07:08:07.381866Z","shell.execute_reply.started":"2025-07-28T07:08:07.372398Z","shell.execute_reply":"2025-07-28T07:08:07.380741Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/store-sales-time-series-forecasting/oil.csv\n/kaggle/input/store-sales-time-series-forecasting/sample_submission.csv\n/kaggle/input/store-sales-time-series-forecasting/holidays_events.csv\n/kaggle/input/store-sales-time-series-forecasting/stores.csv\n/kaggle/input/store-sales-time-series-forecasting/train.csv\n/kaggle/input/store-sales-time-series-forecasting/test.csv\n/kaggle/input/store-sales-time-series-forecasting/transactions.csv\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# input dataset\ntrain = pd.read_csv(\"/kaggle/input/store-sales-time-series-forecasting/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/store-sales-time-series-forecasting/test.csv\")\nstores = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/stores.csv')\nholidays = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/holidays_events.csv', parse_dates=['date'])\noil = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/oil.csv', parse_dates=['date'])\ntransactions = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/transactions.csv', parse_dates=['date'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T07:08:07.383357Z","iopub.execute_input":"2025-07-28T07:08:07.383693Z","iopub.status.idle":"2025-07-28T07:08:09.334301Z","shell.execute_reply.started":"2025-07-28T07:08:07.383660Z","shell.execute_reply":"2025-07-28T07:08:09.333174Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# adjust date formats\ntrain['date'] = pd.to_datetime(train['date'])\ntest['date'] = pd.to_datetime(test['date'])\ntransactions['date'] = pd.to_datetime(transactions['date'])\nholidays['date'] = pd.to_datetime(holidays['date'])\noil['date'] = pd.to_datetime(oil['date'])\n\n# merge the dataset\ntrain = train.merge(stores, on='store_nbr', how='left')\ntest = test.merge(stores, on='store_nbr', how='left')\n\ntrain = train.merge(transactions, on=['date', 'store_nbr'], how='left')\n\ntrain = train.merge(oil, on='date', how='left')\ntest = test.merge(oil, on='date', how='left')\n\nholidays = holidays[['date', 'locale', 'transferred']].rename(columns={'locale': 'holidays_locale'})\ntrain = train.merge(holidays, on='date', how='left', suffixes=('', '_holiday'))\ntest = test.merge(holidays, on='date', how='left', suffixes=('', '_holiday'))\n\ntrain.info()\ntest.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T07:08:09.335397Z","iopub.execute_input":"2025-07-28T07:08:09.335655Z","iopub.status.idle":"2025-07-28T07:08:12.499273Z","shell.execute_reply.started":"2025-07-28T07:08:09.335632Z","shell.execute_reply":"2025-07-28T07:08:12.498321Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3054348 entries, 0 to 3054347\nData columns (total 14 columns):\n #   Column           Dtype         \n---  ------           -----         \n 0   id               int64         \n 1   date             datetime64[ns]\n 2   store_nbr        int64         \n 3   family           object        \n 4   sales            float64       \n 5   onpromotion      int64         \n 6   city             object        \n 7   state            object        \n 8   type             object        \n 9   cluster          int64         \n 10  transactions     float64       \n 11  dcoilwtico       float64       \n 12  holidays_locale  object        \n 13  transferred      object        \ndtypes: datetime64[ns](1), float64(3), int64(4), object(6)\nmemory usage: 326.2+ MB\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 28512 entries, 0 to 28511\nData columns (total 12 columns):\n #   Column           Non-Null Count  Dtype         \n---  ------           --------------  -----         \n 0   id               28512 non-null  int64         \n 1   date             28512 non-null  datetime64[ns]\n 2   store_nbr        28512 non-null  int64         \n 3   family           28512 non-null  object        \n 4   onpromotion      28512 non-null  int64         \n 5   city             28512 non-null  object        \n 6   state            28512 non-null  object        \n 7   type             28512 non-null  object        \n 8   cluster          28512 non-null  int64         \n 9   dcoilwtico       21384 non-null  float64       \n 10  holidays_locale  1782 non-null   object        \n 11  transferred      1782 non-null   object        \ndtypes: datetime64[ns](1), float64(1), int64(4), object(6)\nmemory usage: 2.6+ MB\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# check the missing values\nprint(\"---missing value---\")\nprint(train.isnull().sum())\n\nprint(\"\\n---unique value---\")\nfor col in train:\n    print(f\"{col}:{train[col].nunique()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T07:08:12.501055Z","iopub.execute_input":"2025-07-28T07:08:12.501344Z","iopub.status.idle":"2025-07-28T07:08:14.387453Z","shell.execute_reply.started":"2025-07-28T07:08:12.501323Z","shell.execute_reply":"2025-07-28T07:08:14.386466Z"}},"outputs":[{"name":"stdout","text":"---missing value---\nid                       0\ndate                     0\nstore_nbr                0\nfamily                   0\nsales                    0\nonpromotion              0\ncity                     0\nstate                    0\ntype                     0\ncluster                  0\ntransactions        249117\ndcoilwtico          955152\nholidays_locale    2551824\ntransferred        2551824\ndtype: int64\n\n---unique value---\nid:3000888\ndate:1684\nstore_nbr:54\nfamily:33\nsales:379610\nonpromotion:362\ncity:22\nstate:16\ntype:5\ncluster:17\ntransactions:4993\ndcoilwtico:994\nholidays_locale:3\ntransferred:2\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"#fill in the missing value\ntrain['holidays_locale'] = train['holidays_locale'].fillna(False)\ntrain['transferred'] = train['transferred'].fillna(False)\ntrain['transactions'] = train.groupby('store_nbr')['transactions'].transform(lambda x: x.fillna(x.median()))\ntrain['dcoilwtico'] = train['dcoilwtico'].interpolate(method='linear')\ntrain['dcoilwtico'] = train['dcoilwtico'].fillna(method='ffill').fillna(method='bfill')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T07:08:14.388257Z","iopub.execute_input":"2025-07-28T07:08:14.388491Z","iopub.status.idle":"2025-07-28T07:08:15.577670Z","shell.execute_reply.started":"2025-07-28T07:08:14.388471Z","shell.execute_reply":"2025-07-28T07:08:15.576492Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/1759415756.py:3: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  train['transferred'] = train['transferred'].fillna(False)\n/tmp/ipykernel_36/1759415756.py:6: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  train['dcoilwtico'] = train['dcoilwtico'].fillna(method='ffill').fillna(method='bfill')\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# check the missing values\nprint(\"---missing value---\")\nprint(train.isnull().sum())\n\nprint(\"\\n---unique value---\")\nfor col in train:\n    print(f\"{col}:{train[col].nunique()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T07:08:15.578636Z","iopub.execute_input":"2025-07-28T07:08:15.578956Z","iopub.status.idle":"2025-07-28T07:08:17.393315Z","shell.execute_reply.started":"2025-07-28T07:08:15.578934Z","shell.execute_reply":"2025-07-28T07:08:17.392361Z"}},"outputs":[{"name":"stdout","text":"---missing value---\nid                 0\ndate               0\nstore_nbr          0\nfamily             0\nsales              0\nonpromotion        0\ncity               0\nstate              0\ntype               0\ncluster            0\ntransactions       0\ndcoilwtico         0\nholidays_locale    0\ntransferred        0\ndtype: int64\n\n---unique value---\nid:3000888\ndate:1684\nstore_nbr:54\nfamily:33\nsales:379610\nonpromotion:362\ncity:22\nstate:16\ntype:5\ncluster:17\ntransactions:5001\ndcoilwtico:933305\nholidays_locale:4\ntransferred:2\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"#extract temporal feature\ntrain['year'] = train['date'].dt.year\ntrain['month'] = train['date'].dt.month\ntrain['day'] = train['date'].dt.day\ntrain['dayofweek'] = train['date'].dt.dayofweek\ntrain['weekofyear'] = train['date'].dt.isocalendar().week.astype(int)\ntrain['is_weekend'] = train['dayofweek'].isin([5, 6]).astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T07:08:17.394191Z","iopub.execute_input":"2025-07-28T07:08:17.394456Z","iopub.status.idle":"2025-07-28T07:08:17.904429Z","shell.execute_reply.started":"2025-07-28T07:08:17.394434Z","shell.execute_reply":"2025-07-28T07:08:17.903477Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"#extract temporal feature\ntrain['year'] = train['date'].dt.year\ntrain['month'] = train['date'].dt.month\ntrain['day'] = train['date'].dt.day\ntrain['dayofweek'] = train['date'].dt.dayofweek\ntrain['weekofyear'] = train['date'].dt.isocalendar().week.astype(int)\ntrain['is_weekend'] = train['dayofweek'].isin([5, 6]).astype(int)\n\n\n#adjust the order of dataset\ntrain_order = [\n    'id', 'date','year','month','day','dayofweek','weekofyear','is_weekend', 'holidays_locale', 'transferred', \n    'dcoilwtico',\n    'store_nbr', 'city', 'state', 'type', 'cluster',\n    'onpromotion', 'family', 'transactions','sales'\n]\n\ntest_order = [\n    'id', 'date','year','month','day','dayofweek','weekofyear','is_weekend','holidays_locale', 'transferred', \n    'dcoilwtico',\n    'store_nbr',  'city', 'state', 'type', 'cluster',\n   'onpromotion', 'family'\n]\n\ntrain = train[train_order]\ntest = test[test_order]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T07:08:17.905215Z","iopub.execute_input":"2025-07-28T07:08:17.905483Z","iopub.status.idle":"2025-07-28T07:08:18.759373Z","shell.execute_reply.started":"2025-07-28T07:08:17.905462Z","shell.execute_reply":"2025-07-28T07:08:18.758205Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3920537293.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_order\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_order\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6252\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6254\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: \"['year', 'month', 'day', 'dayofweek', 'weekofyear', 'is_weekend'] not in index\""],"ename":"KeyError","evalue":"\"['year', 'month', 'day', 'dayofweek', 'weekofyear', 'is_weekend'] not in index\"","output_type":"error"}],"execution_count":19},{"cell_type":"code","source":"train.info","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T07:08:25.952739Z","iopub.execute_input":"2025-07-28T07:08:25.953126Z","iopub.status.idle":"2025-07-28T07:08:25.968025Z","shell.execute_reply.started":"2025-07-28T07:08:25.953076Z","shell.execute_reply":"2025-07-28T07:08:25.966989Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"<bound method DataFrame.info of               id       date  year  month  day  dayofweek  weekofyear  \\\n0              0 2013-01-01  2013      1    1          1           1   \n1              1 2013-01-01  2013      1    1          1           1   \n2              2 2013-01-01  2013      1    1          1           1   \n3              3 2013-01-01  2013      1    1          1           1   \n4              4 2013-01-01  2013      1    1          1           1   \n...          ...        ...   ...    ...  ...        ...         ...   \n3054343  3000883 2017-08-15  2017      8   15          1          33   \n3054344  3000884 2017-08-15  2017      8   15          1          33   \n3054345  3000885 2017-08-15  2017      8   15          1          33   \n3054346  3000886 2017-08-15  2017      8   15          1          33   \n3054347  3000887 2017-08-15  2017      8   15          1          33   \n\n         is_weekend holidays_locale  transferred  dcoilwtico  store_nbr  \\\n0                 0        National        False       93.14          1   \n1                 0        National        False       93.14          1   \n2                 0        National        False       93.14          1   \n3                 0        National        False       93.14          1   \n4                 0        National        False       93.14          1   \n...             ...             ...          ...         ...        ...   \n3054343           0           Local        False       47.57          9   \n3054344           0           Local        False       47.57          9   \n3054345           0           Local        False       47.57          9   \n3054346           0           Local        False       47.57          9   \n3054347           0           Local        False       47.57          9   \n\n          city      state type  cluster  onpromotion  \\\n0        Quito  Pichincha    D       13            0   \n1        Quito  Pichincha    D       13            0   \n2        Quito  Pichincha    D       13            0   \n3        Quito  Pichincha    D       13            0   \n4        Quito  Pichincha    D       13            0   \n...        ...        ...  ...      ...          ...   \n3054343  Quito  Pichincha    B        6            0   \n3054344  Quito  Pichincha    B        6            1   \n3054345  Quito  Pichincha    B        6          148   \n3054346  Quito  Pichincha    B        6            8   \n3054347  Quito  Pichincha    B        6            0   \n\n                             family  transactions     sales  \n0                        AUTOMOTIVE        1746.0     0.000  \n1                         BABY CARE        1746.0     0.000  \n2                            BEAUTY        1746.0     0.000  \n3                         BEVERAGES        1746.0     0.000  \n4                             BOOKS        1746.0     0.000  \n...                             ...           ...       ...  \n3054343                     POULTRY        2155.0   438.133  \n3054344              PREPARED FOODS        2155.0   154.553  \n3054345                     PRODUCE        2155.0  2419.729  \n3054346  SCHOOL AND OFFICE SUPPLIES        2155.0   121.000  \n3054347                     SEAFOOD        2155.0    16.000  \n\n[3054348 rows x 20 columns]>"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\n\n# split the train set and test set\ntrain_data = train[train['date'] < '2017-01-01']\nvalid_data = train[train['date'] >= '2017-01-01']\n\n#delete unnecessary column\ntrain.drop(columns=['date','id'], inplace=True)\ntest.drop(columns=['date','id'], inplace=True)\n\n# split categorical and numerical columns\ncat_cols = ['store_nbr', 'family', 'city', 'state', 'type', 'cluster', 'holidays_locale', 'transferred']\nfor col in cat_cols:\n    le = LabelEncoder()\n    train[col] = le.fit_transform(train[col].astype(str))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T07:08:18.762288Z","iopub.status.idle":"2025-07-28T07:08:18.762592Z","shell.execute_reply.started":"2025-07-28T07:08:18.762461Z","shell.execute_reply":"2025-07-28T07:08:18.762474Z"}},"outputs":[],"execution_count":null}]}